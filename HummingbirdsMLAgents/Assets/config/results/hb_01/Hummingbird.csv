Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,0.032476198,999.0,0.0,0.0,1.0
20000,1.4189383,0.024760943,999.0,0.0,0.0,1.0
30000,1.418574,0.20817614,999.0,-0.13636363636363635,-0.13636363636363635,1.0
40000,1.4185332,0.21336246,999.0,0.0,0.0,1.0
50000,1.4186635,0.19163175,999.0,0.0,0.0,1.0
60000,1.4186877,0.21011221,999.0,0.0,0.0,1.0
70000,1.4183321,0.19837537,999.0,-2.0,-2.0,1.0
80000,1.4181696,0.21873352,999.0,-4.375,-4.375,1.0
90000,1.4174751,0.20065114,999.0,-1.6363636363636365,-1.6363636363636365,1.0
100000,1.416996,0.16134295,999.0,0.0,0.0,1.0
110000,1.4165245,0.16178593,999.0,0.0,0.0,1.0
120000,1.4160544,0.16762194,999.0,-0.09090909090909091,-0.09090909090909091,1.0
130000,1.4155834,0.1637127,999.0,-0.9285714285714286,-0.9285714285714286,1.0
140000,1.4149112,0.14039858,999.0,0.0,0.0,1.0
150000,1.4144837,0.14623192,999.0,0.0,0.0,1.0
160000,1.4133179,0.1336176,999.0,0.0,0.0,1.0
170000,1.4131451,0.12911579,999.0,0.013852626085281372,0.013852626085281372,1.0
180000,1.4125029,0.119481586,999.0,0.0,0.0,1.0
190000,1.4124672,0.11254056,999.0,0.0,0.0,1.0
200000,1.4121742,0.105169296,999.0,0.0,0.0,1.0
210000,1.4121742,0.10845466,999.0,0.0,0.0,1.0
220000,1.411494,0.09611716,999.0,0.0,0.0,1.0
